<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ruihan Gao</title>
  
  <meta name="author" content="Ruihan Gao">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="data/RuihanGao_icon.jpg">
  
</head>

<body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr style="padding:0px">
            <td style="padding:0px">
                <!-- Self Intro -->
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p style="text-align:center">
                            <name>Ruihan Gao (高睿晗)</name>
                        </p>
                            I am a PhD Student at Carnegie Mellon University, advised by <a href="https://www.cs.cmu.edu/~junyanz/">Prof. Jun-Yan Zhu</a> and <a href="http://robotouch.ri.cmu.edu/yuanwz/">Prof. Wenzhen Yuan</a>. My research interests lie in the intersection of machine learning, tactile sensing, and haptic-rendering.
                        </p>
                        <p>
                            I received B.Eng.(Hons) in Electrical and Electronic Engineering from Nanyang Technological University, Singapore in 2020. After graduation, I joined A*STAR Institute for Infocomm Research (I2R) as a Research Engineer. I am grateful for <a href="https://dr.ntu.edu.sg/cris/rp/rp00141">Prof. Zhiping Lin</a> who led me into academic research and I have spent great time working with <a href="https://yan-wu.com/">Dr. Yan Wu</a>&nbsp;and collegues at A*STAR on robotic tactile sensing projects. 
                        </p>
                        <p>
                            I envision robots interacting with humans naturally and aspires to realize it with multi-modal perception and rendering powered by machine learning.
                        </p>
                        <p style="text-align:center">
                            <a href="mailto:ruihang@andrew.cmu.edu">Email</a> &nbsp/&nbsp
                            <a href="data/RuihanGao_CV.pdf">CV</a> &nbsp/&nbsp
                            <a href="https://github.com/RuihanGao">Github</a> &nbsp/&nbsp
                            <a href="https://scholar.google.com/citations?hl=en&user=rbfajPIAAAAJ">Google Scholar</a> &nbsp/&nbsp
                            <a href="https://www.linkedin.com/in/ruihan-gao/">Linkedin</a>
                        </p>
                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="data/RuihanGao.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="data/RuihanGao_circle.jpg" class="hoverZoomLink"></a>
                    </td>
                </tr>
                </tbody>
                </table>
                
                <!-- Title "Publications" -->
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr>
                        <td style="padding:20px;width:100%;vertical-align:middle">
                            <heading>Selected Publication</heading>
                        </td>
                    </tr>
                </tbody>
                </table>
                
                <!-- One row per publication -->
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr>
                        <!-- <tr onmouseout="bakedsdf_stop()" onmouseover="bakedsdf_start()">
                            <td style="padding:20px;width:25%;vertical-align:middle">
                                <div class="one">
                                <div class="two" id='bakedsdf_image'><video  width=100% height=100% muted autoplay loop>
                                <source src="images/bakedsdf_after.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                                </video></div>
                                <img src='images/bakedsdf_before.jpg' width="160">
                                </div>
                                <script type="text/javascript">
                                function bakedsdf_start() {
                                    document.getElementById('bakedsdf_image').style.opacity = "1";
                                }
    
                                function bakedsdf_stop() {
                                    document.getElementById('bakedsdf_image').style.opacity = "0";
                                }
                                bakedsdf_stop()
                                </script> -->
                            <td>
                            <!-- Insert an image here -->
                            <img src='images/TactileDreamFusion_teaser.png' width="100%">
                            </td>
    
                            <td style="padding:20px;width:75%;vertical-align:middle">
                                <a href="https://ruihangao.github.io/TactileDreamFusion/">
                                <papertitle>Tactile DreamFusion: Exploiting Tactile Sensing for 3D Generation</papertitle>
                                </a>
                                <br>
                                <strong>Ruihan Gao</strong>,
                                <a href="https://dunbar12138.github.io/">Kangle Deng</a>,
                                <a href="https://gengshan-y.github.io/">Gengshan Yang</a>,
                                <a href="https://siebelschool.illinois.edu/about/people/all-faculty/yuanwz">Wenzhen Yuan</a>,
                                <a href="https://www.cs.cmu.edu/~junyanz/">Jun-Yan Zhu</a>,
                                <br>
                                <em>NeurIPS</em>, 2024
                                <br>
                                <a href="https://ruihangao.github.io/TactileDreamFusion/">Webpage</a>
                                /
                                <a href="https://arxiv.org/abs/2412.06785">Paper</a>
                                /
                                <a href="https://github.com/RuihanGao/TactileDreamFusion">Code</a>
                                /
                                <a href="https://huggingface.co/datasets/Ruihan28/TactileDreamFusion">Data</a>
                                <p></p>
                                <p>
                                    We exploit high-resolution tactile sensing with diffusion-based image priors to enhance fine geometric details for text- or image-to-3D generation.
                                </p>
                            </td>
                    </tr>
                    
                    <tr>
                    <!-- <tr onmouseout="bakedsdf_stop()" onmouseover="bakedsdf_start()">
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <div class="one">
                            <div class="two" id='bakedsdf_image'><video  width=100% height=100% muted autoplay loop>
                            <source src="images/bakedsdf_after.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                            </video></div>
                            <img src='images/bakedsdf_before.jpg' width="160">
                            </div>
                            <script type="text/javascript">
                            function bakedsdf_start() {
                                document.getElementById('bakedsdf_image').style.opacity = "1";
                            }

                            function bakedsdf_stop() {
                                document.getElementById('bakedsdf_image').style.opacity = "0";
                            }
                            bakedsdf_stop()
                            </script> -->
                        <td>
                        <!-- Insert an image here -->
                        <img src='images/visual_tactile_synthesis_teaser.png' width="100%">
                        </td>

                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://visual-tactile-synthesis.github.io/">
                            <papertitle>Controllable Visual-Tactile Synthesis</papertitle>
                            </a>
                            <br>
                            <strong>Ruihan Gao</strong>,
                            <a href="http://robotouch.ri.cmu.edu/yuanwz/">Wenzhen Yuan</a>,
                            <a href="https://www.cs.cmu.edu/~junyanz/">Jun-Yan Zhu</a>,
                            <br>
                            <em>ICCV</em>, 2023
                            <br>
                            <a href="https://visual-tactile-synthesis.github.io/">Webpage</a>
                            /
                            <a href="https://arxiv.org/abs/2305.03051">Paper</a>
                            /
                            <a href="https://github.com/RuihanGao/visual-tactile-synthesis">Code</a>
                            /
                            <a href="https://drive.google.com/file/d/1VlgYpDSxQP70sYpFERHuzKnTNIH4Gf4s/view?usp=share_link">Data</a>
                            <p></p>
                            <p>
                                We synthesize visual appearance and tactile geometry of different materials, given a handcrafted or DALL⋅E 2 sketch, and render the multi-modal output on a haptic screen called TanvasTouch.
                            </p>
                        </td>
                    </tr>
                    
                    <tr>
                        <td>
                        <img src='images/zandonati2023investigating_teaser.png' width="100%">
                        </td>

                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://arxiv.org/abs/2305.00596">
                            <papertitle>Investigating Vision Foundational Models for Tactile Representation Learning</papertitle>
                            </a>
                            <br>
                            <a href="https://www.benzandonati.co.uk">Ben Zandonati</a>, <a href="https://ruohanw.github.io/">Ruohan Wang</a>, <strong>Ruihan Gao</strong>, <a href="https://yan-wu.com/">Yan Wu</a>,
                            <br>
                            <em>arxiv</em>, 2023
                            <br>
                            <a href="files/zandonati2023investigating.pdf">Paper</a>
                            <p></p>
                            <!-- <p>
                                Short description of the paper.
                            </p> -->
                        </td>
                    </tr>

                    <tr>
                        <td>
                        <img src='images/gao2021explainability_teaser.png' width="100%">
                        </td>

                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://ieeexplore.ieee.org/document/9636380">
                            <papertitle>On Explainability and Sensor-Adaptability of a Robot Tactile Texture Representation Using a Two-Stage Recurrent Networks</papertitle>
                            </a>
                            <br>
                            <strong>Ruihan Gao<sup>&#42;</sup></strong>,
                            <a href="https://www.linkedin.com/in/tian-tian-52435b190/?trk=public_profile_browsemap&originalSubdomain=sg">Tian Tian<sup>&#42;</sup></a>,
                            <a href="https://dr.ntu.edu.sg/cris/rp/rp00141">Zhiping Lin</a>,
                            <a href="https://yan-wu.com/">Yan Wu</a>,
                            <br>
                            <em>IROS</em>, 2021
                            <br>
                            <a href="files/gao2021explainability.pdf">Paper</a>
                            <p></p>
                            <!-- <p>
                                Short description of the paper.
                            </p> -->
                        </td>
                    </tr>

                    <tr>
                        <td>
                        <img src='images/gao2020supervised_teaser.png' width="100%">
                        </td>

                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://ieeexplore.ieee.org/document/9341111">
                            <papertitle>Supervised Autoencoder Joint Learning on Heterogeneous Tactile Sensory Data: Improving Material Classification Performance</papertitle>
                            </a>
                            <br>
                            <strong>Ruihan Gao</strong>,
                            <a href="https://tasbolat.com/">Tasbolat Taunyazov</a>,
                            <a href="https://dr.ntu.edu.sg/cris/rp/rp00141">Zhiping Lin</a>,
                            <a href="https://yan-wu.com/">Yan Wu</a>,
                            <br>
                            <em>IROS</em>, 2020
                            <br>
                            <a href="files/gao2020supervised.pdf">Paper</a>
                            <p></p>
                            <!-- <p>
                                Short description of the paper.
                            </p> -->
                        </td>
                    </tr>

                    <tr>
                        <td>
                        <img src='images/taunyazov2020fast_teaser.png' width="100%">
                        </td>

                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://ieeexplore.ieee.org/document/9340693">
                            <papertitle>Fast Texture Classification Using Tactile Neural Coding and Spiking Neural Network</papertitle>
                            </a>
                            <br>
                            <a href="https://tasbolat.com/">Tasbolat Taunyazov</a>,
                            <a href="https://scholar.google.com.sg/citations?user=-UVVOA8AAAAJ&hl=en">Yansong Chua</a>,
                            <strong>Ruihan Gao</strong>,
                            <a href="https://haroldsoh.com/">Harold Soh</a>,
                            <a href="https://yan-wu.com/">Yan Wu</a>,
                            <br>
                            <em>IROS</em>, 2020
                            <br>
                            <a href="files/taunyazov2020fast.pdf">Paper</a>
                            <p></p>
                            <!-- <p>
                                Short description of the paper.
                            </p> -->
                        </td>
                    </tr>
                    
                </tbody>
                </table>

                <!-- Toggle list for previous publications -->
                <button type="button" class="collapsible">Others</button>
                <div class="content">
                    <!-- One row per publication -->
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


                        <tr>
                            <td>
                            <img src='images/gauthier2021towards_teaser.png' width="100%">
                            </td>

                            <td style="padding:20px;width:75%;vertical-align:middle">
                                <a href="https://link.springer.com/chapter/10.1007/978-3-030-90525-5_18">
                                <papertitle>Towards a Programming-Free Robotic System for Assembly Tasks Using Intuitive Interactions</papertitle>
                                </a>
                                <br>
                                Nicolas Gauthier,
                                Wenyu Liang,
                                Qianli Xu,
                                Fen Fang, 
                                Liyuan Li,
                                <strong>Ruihan Gao</strong>,
                                <a href="https://yan-wu.com/">Yan Wu</a>,
                                Joo Hwee Lim
                                <br>
                                ICSR, 2021.
                                <br>
                                <a href="files/gauthier2021towards.pdf">Paper</a>
                                <p></p>
                                <!-- <p>
                                    Short description of the paper.
                                </p> -->
                            </td>
                        </tr>

                        <tr>
                            <td>
                            <img src='images/peng2021classification_teaser.png' width="100%">
                            </td>

                            <td style="padding:20px;width:75%;vertical-align:middle">
                                <a href="https://ieeexplore.ieee.org/abstract/document/9630147">
                                <papertitle>Classification of Non-tumorous Facial Pigmentation Disorders Using Generative Adversarial Networks and Improved SMOTE</papertitle>
                                </a>
                                <br>
                                Jiawei Peng,
                                <strong>Ruihan Gao</strong>,
                                Steven Thng,
                                <a href="https://scholar.google.com.sg/citations?user=KRxoQtIAAAAJ&hl=en">Weimin Huang</a>,
                                <a href="https://dr.ntu.edu.sg/cris/rp/rp00141">Zhiping Lin</a>,
                                <br>
                                IEEE Engineering in Medicine & Biology Society (EMBC), 2021.
                                <br>
                                <p></p>
                                <!-- <p>
                                    Short description of the paper.
                                </p> -->
                            </td>
                        </tr>

                        <tr>
                            <td>
                            <img src='images/runtime_safety_teaser.png' width="100%">
                            </td>

                            <td style="padding:20px;width:75%;vertical-align:middle">
                                <a href="https://arxiv.org/abs/2008.07667">
                                <papertitle>Runtime-safety-guided policy repair</papertitle>
                                </a>
                                <br>
                                <a href="https://sites.google.com/view/zwc662/">Weichao Zhou</a>,
                                <strong>Ruihan Gao</strong>,
                                Kim BaekGy,
                                Eunsuk Kang,
                                <a href="https://www.bu.edu/eng/profile/39799/">Wenchao Li</a>,
                                <br>
                                <em>RV</em>, 2020
                                <br>
                                <a href="https://arxiv.org/pdf/2008.07667.pdf">Paper</a>
                                <p></p>
                                <!-- <p>
                                    Short description of the paper.
                                </p> -->
                            </td>
                        </tr>

                        <tr>
                            <td>
                            <img src='images/nguyen2019biomedical_teaser.png' width="100%">
                            </td>

                            <td style="padding:20px;width:75%;vertical-align:middle">
                                <a href="https://link.springer.com/article/10.1007/s12652-019-01276-4">
                                <papertitle>Biomedical image classification based on a feature concatenation and ensemble of deep CNNs</papertitle>
                                </a>
                                <br>
                                Long D. Nguyen,
                                <strong>Ruihan Gao</strong>,
                                <a href="https://thomaslin1990.github.io/">Dongyun Lin</a>,
                                <a href="https://dr.ntu.edu.sg/cris/rp/rp00141">Zhiping Lin</a>,
                                <br>
                                Journal of Ambient Intelligence and Humanized Computing, 2019.
                                <br>
                                <a href="files/nguyen2019biomedical.pdf">Paper</a>
                                <p></p>
                                <!-- <p>
                                    Short description of the paper.
                                </p> -->
                            </td>
                        </tr>
                        
                        <tr>
                            <td>
                            <img src='images/gao2019classification_teaser.png' width="100%">
                            </td>

                            <td style="padding:20px;width:75%;vertical-align:middle">
                                <a href="https://ieeexplore.ieee.org/document/8702334">
                                <papertitle>Classification of Non-Tumorous Facial Pigmentation Disorders using Deep Learning and SMOTE </papertitle>
                                </a>
                                <br>
                                <strong>Ruihan Gao</strong>,
                                Jiawei Peng,
                                Nguyen Long, 
                                Yunfeng Liang,
                                Steven Thng,
                                <a href="https://dr.ntu.edu.sg/cris/rp/rp00141">Zhiping Lin</a>,
                                <br>
                                ISCAS, 2019.
                                <br>
                                <a href="files/gao2019classification.pdf">Paper</a>
                                <p></p>
                                <!-- <p>
                                    Short description of the paper.
                                </p> -->
                            </td>
                        </tr>

                        <tr>
                            <td>
                            <img src='images/peng2019classification_teaser.png' width="100%">
                            </td>

                            <td style="padding:20px;width:75%;vertical-align:middle">
                                <a href="https://ieeexplore.ieee.org/abstract/document/8802993">
                                <papertitle>Classification of Non-Tumorous Facial Pigmentation Disorders Using Improved SMOTE and Transfer Learning</papertitle>
                                </a>
                                <br>
                                Jiawei Peng,
                                <strong>Ruihan Gao</strong>,
                                Nguyen Long, 
                                Yunfeng Liang,
                                Steven Thng,
                                <a href="https://dr.ntu.edu.sg/cris/rp/rp00141">Zhiping Lin</a>,
                                <br>
                                ISCAS, 2019.
                                <br>
                                <a href="files/peng2019classification.pdf">Paper</a>
                                <p></p>
                                <!-- <p>
                                    Short description of the paper.
                                </p> -->
                            </td>
                        </tr>
                    </tbody>
                    </table>
                </div>
            
                <!-- Denote equal contribution -->
                <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
                    <p align="left">
                      <font size="2">
                        <sup>&#42;</sup> denotes equal contribution
                      </font>
                </table>

                <!-- Acknowledgment for template -->
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                      <td>
                        <br>
                        <p align="right">
                          <font size="2">
                            <a href="http://www.cs.berkeley.edu/~barron/">web template taken from this website</a>
                          </font>
                        </p>
                      </td>
                    </tr>
                </table>
            
            </td>
        </tr>
    </table>


<!-- Default Statcounter code for My Personal Webpage http://RuihanGao.github.io-->
<script type="text/javascript">
    var sc_project=12888430; 
    var sc_invisible=1; 
    var sc_security="99474f23"; 
    </script>
    <script type="text/javascript"
    src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript><div class="statcounter"><a title="Web Analytics Made Easy -
    Statcounter" href="https://statcounter.com/" target="_blank"><img
    class="statcounter" src="https://c.statcounter.com/12888430/0/99474f23/1/"
    alt="Web Analytics Made Easy - Statcounter"
    referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
<!-- End of Statcounter Code -->

<script src="script.js"></script>
</body>

</html>
